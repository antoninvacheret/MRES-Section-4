{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a52ab7-163f-432a-99e7-dce81f45f1ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Section 4 - Computer vision based machine learning #\n",
    "## Building CNNs with pyTorch ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaa24db-c3f1-4bab-8ce8-418368d1512d",
   "metadata": {},
   "source": [
    "In this second part we will:\n",
    "\n",
    "Star with: \n",
    "* look at the MNIST dataset\n",
    "* construct datasets, loaders and visualise the data\n",
    "* Build a MLP to classify the MNIST dataset\n",
    "\n",
    "and then:\n",
    "* Build a CNN based on the MNIST dataset features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd359d-c8f1-406b-b27e-4434f058e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import copy\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb8bc2f-7434-42e9-a12a-b4e239b14901",
   "metadata": {},
   "source": [
    "We are going to use here the datasets readily available in pytorch using ```torchvision.datasets```. We will need to define if the training set is used to train or test. We will add some transformations that are already available (ToTensor() and Normalise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2853f979-ed53-4530-83fe-a3a0dc95d101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = torchvision.datasets.MNIST(root='./data', download=True, train=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "#train = torchvision.datasets.MNIST(root='./data', download=True, train=True, transform=transforms.Compose([transforms.ToTensor(),\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc931f1b-ce2b-4cde-bf3f-fe893e1a2ae9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we have a training sample based on MNIST we can instantiate a dataloader that will be used to provide training data to our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416a9ca-2ea1-4dd7-9a81-3a44d7f31b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train, shuffle=True, batch_size=10) #we can set the batch size for each interation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab206d84-fed7-4591-a820-46fe9e018b71",
   "metadata": {
    "tags": []
   },
   "source": [
    "It is now possible to visualise easily our dataset using the dataloader and explore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058fc067-59d5-40e7-9951-3718d42922d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(14, 8))\n",
    "ax = ax.flatten()\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(\"image shape:\", images.shape, \"\\n label shape:\", labels.shape)\n",
    "for i in range(0, 10):\n",
    "    plottable_image = images[i].squeeze()\n",
    "    ax[i].imshow(plottable_image, cmap='gray')\n",
    "    ax[i].set_title(\"Label: {}\".format(labels[i]))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650ac8f1-ce63-46ff-bd1f-eefa19d62afd",
   "metadata": {},
   "source": [
    "Exercise: \n",
    "* write a Load_MNIST function that load the MNIST dataset both for training and testing and return four sets ```train,test,train_loader, test_loader```.\n",
    "* write a short function ```visualize_MNIST``` to visualise any number of digits using the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33824d2c-90ed-48fb-baa3-3758f11dd0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9194a8-5976-45b9-acbd-b31d2157872d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35f926-af8c-4c49-847a-5189e8994518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize MNISt\n",
    "train, test, train_loader, test_loader = load_MNIST()\n",
    "visualize_MNIST(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b04db-5227-4208-a043-3908a1759ba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Let's now build a MLP based on a few layers before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8257ed5-a001-41c8-83b5-1c287751813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "  def __init__(self):\n",
    "    super(Net,self).__init__()\n",
    "    self.input_layer = nn.Linear(784, 1000, bias=False)\n",
    "    self.hidden1_layer = nn.Linear(1000, 1000, bias=False)\n",
    "    self.hidden2_layer = nn.Linear(1000, 500, bias=False)\n",
    "    self.hidden3_layer = nn.Linear(500, 200, bias=False)\n",
    "    self.hidden4_layer = nn.Linear(200, 10, bias=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.input_layer(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.hidden1_layer(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.hidden2_layer(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.hidden3_layer(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.hidden4_layer(x)\n",
    "    output = F.log_softmax(x, dim=1)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b77047c-e1e8-4f74-b92a-4709256b979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs=3, learning_rate=0.001):\n",
    "  \"\"\"Function to train a neural net\"\"\"\n",
    "\n",
    "  lossFunction = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  time0 = time()\n",
    "  total_samples = 0 \n",
    "\n",
    "  for e in range(epochs):\n",
    "    print(\"Starting epoch\", e)\n",
    "    total_loss = 0\n",
    "\n",
    "    for idx, (images,labels) in enumerate(train_loader):\n",
    "      images = images.view(images.shape[0],-1) # flatten\n",
    "      optimizer.zero_grad() # forward pass\n",
    "      output = model(images)\n",
    "      loss = lossFunction(output,labels) # calculate loss\n",
    "      loss.backward() # backpropagate\n",
    "      optimizer.step() # update weights\n",
    "\n",
    "      total_samples += labels.size(0)\n",
    "      total_loss += loss.item()\n",
    "\n",
    "      if idx % 100 == 0:\n",
    "        print(\"Running loss:\", total_loss)\n",
    "\n",
    "  final_time = (time()-time0)/60 \n",
    "  print(\"Model trained in \", final_time, \"minutes on \", total_samples, \"samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc935044-4ab5-4204-849b-8dbb6afe92bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "train(model, train_loader, 3) # 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f982a7-14ee-4ba3-863d-98bb40050879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "  \"\"\"Test neural net\"\"\"\n",
    "\n",
    "  correct = 0\n",
    "  total = 0 \n",
    "\n",
    "  with torch.no_grad():\n",
    "    for idx, (images, labels) in enumerate(test_loader):\n",
    "      images = images.view(images.shape[0],-1) # flatten\n",
    "      output = model(images)\n",
    "      values, indices = torch.max(output.data, 1)\n",
    "      total += labels.size(0)\n",
    "      correct += (labels == indices).sum().item()\n",
    "\n",
    "    acc = correct / total * 100\n",
    "    # print(\"Accuracy: \", acc, \"% for \", total, \"training samples\")\n",
    "\n",
    "  return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c2785-fd6f-43e2-93ab-7cc9db54a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = test(model, test_loader)\n",
    "print(\"The accuracy of our vanilla NN is\", acc, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20f365-3206-4185-bc30-75ac2343dc13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
